{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by: Brandon Susini\n",
    "# Date: 2/14/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "### Assemble and clean data from all 5 groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries\n",
    "<ul>\n",
    "<li>csv allows us to work with csv file types easily.</li>\n",
    "<li>pandas gives us access to many data science related tools like data frames</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, pandas as pd\n",
    "# Make a list of all the expected column names for the documents\n",
    "column_names = ['Url', 'Date', 'Content', 'Id', 'User', 'Reply Count',\n",
    "       'Retweet Count', 'Like Count', 'Quote Count', 'Conversation Id',\n",
    "       'Language', 'Source', 'Coordinates']\n",
    "# Convert all the names to lowercase to make it easier in the future.\n",
    "for index, name in enumerate(column_names):\n",
    "       column_names[index] = name.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each csv file into a dataframe.<br>\n",
    "<strong>Note:</strong>\n",
    "Some groups have bugged column names and other issues.<br>\n",
    "For this reason we have to validate the order and value of the \n",
    "column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  vs.  13\n",
      "14  vs.  13\n",
      "12  vs.  13\n",
      "14  vs.  13\n",
      "14  vs.  13\n"
     ]
    }
   ],
   "source": [
    "# List to hold each groups documents\n",
    "all_docs = []\n",
    "# Iterate 5 times in order load in all the groups csv files\n",
    "for index in range(1,6):\n",
    "    # Build the path for the current document\n",
    "    current_file = f\"../all_dirty_docs/tweets_{index}.csv\"\n",
    "    # Load and save the document into a variable\n",
    "    this_document = pd.read_csv(filepath_or_buffer=current_file)\n",
    "    # Create a dictionary that has\n",
    "    # The column name as a key, and the lowered column name as a value\n",
    "    column_dict = {}\n",
    "    for name in this_document.columns.values:\n",
    "        column_dict[name] = name.lower()\n",
    "    # Rename all the columns to their lowered version\n",
    "    this_document.rename(columns=column_dict,inplace=True)\n",
    "    # Add the document to the tweets_list list.\n",
    "    all_docs.append(this_document)\n",
    "    # First, check to see if the number of columns matches.\n",
    "    print(len(this_document.columns.values), \" vs. \",len(column_names))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unnamed: 0', 'url', 'date', 'content', 'id', 'user', 'reply count',\n",
      "       'retweet count', 'like count', 'quote count', 'conversation id',\n",
      "       'language', 'source', 'coordinates'],\n",
      "      dtype='object')\n",
      "Index(['url', 'date', 'content', 'id', 'user', 'reply count', 'retweet count',\n",
      "       'like count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates', 'unnamed: 13'],\n",
      "      dtype='object')\n",
      "Index(['date', 'user', 'content', 'like count', 'id', 'reply count',\n",
      "       'retweet count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n",
      "Index(['unnamed: 0', 'url', 'date', 'content', 'user', 'reply count',\n",
      "       'retweet count', 'like count', 'quote count', 'id', 'language',\n",
      "       'source', 'coordinates', 'dashes'],\n",
      "      dtype='object')\n",
      "Index(['unnamed: 0', 'url', 'date', 'content', 'id', 'user', 'reply count',\n",
      "       'retweet count', 'like count', 'quote count', 'conversation id',\n",
      "       'language', 'source', 'coordinates'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#%%script echo skipping\n",
    "for x in range(0,5):\n",
    "    print(all_docs[x].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows that all the documents need to be fixed.\n",
    "\n",
    "Because our data is inconsistent, we need to re-organize it.\n",
    "We start by determining if the group removed the label headers for each of the 200 tweets.\n",
    "If a document doesn't have a max ID of ~1200 then we can assume the ID's reset at 199.\n",
    "\n",
    "Furthermore, we must ensure that each document has the same order of the columns so we can join them cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows before: 1208\n",
      "Num of rows after: 1200\n",
      "Num of rows before: 1031\n",
      "Num of rows after: 1031\n",
      "Num of rows before: 1208\n",
      "Num of rows after: 1200\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the maximum \"ID\" is for a frame.\n",
    "# Before we can do this we need to determine what column is the \n",
    "# bugged \"ID\" column.\n",
    "# In the case of tweets_1, it is the column \"unnamed: 0\"\n",
    "# Therefore, any document with a column named \"unnamed: 0\"\n",
    "# will need to undergo this process\n",
    "\n",
    "# REFACTOR THIS SO I CAN CALL IT AS A FUNCTION AND IT WILL TEST\n",
    "# ALL DOCUMENTS WITHIN \n",
    "header_docs = [all_docs[0],all_docs[3],all_docs[4]]\n",
    "my_max = 0\n",
    "for doc in header_docs:\n",
    "    print(f\"Num of rows before: {doc.shape[0]}\")\n",
    "    # Removes all instances of header columns by removing any row where \"Unnamed: 0\" == NaN\n",
    "    doc.dropna(subset=[\"unnamed: 0\"], inplace=True)\n",
    "    # Now remove the column all together and re-index the data frame.\n",
    "    doc.drop(labels=\"unnamed: 0\",axis=1,inplace=True)\n",
    "    doc.reset_index(inplace=True,drop=True)\n",
    "    # Finally, drop the created \"index\" column.\n",
    "    print(f\"Num of rows after: {doc.shape[0]}\")\n",
    "all_docs[1].drop(labels=\"unnamed: 13\",axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "# Following this the documents 1 and 5 should be fixed and correctly indexed\n",
    "# and stripped of the problem columns\n",
    "#\n",
    "# We still need to fix document 4 however.\n",
    "\n",
    "# Same thing - Reminder\n",
    "# print(type(tweets_list[0].Url))\n",
    "# print(type(tweets_list[0][\"Url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'date', 'content', 'id', 'user', 'reply count', 'retweet count',\n",
      "       'like count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n",
      "Index(['url', 'date', 'content', 'id', 'user', 'reply count', 'retweet count',\n",
      "       'like count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n",
      "Index(['date', 'user', 'content', 'like count', 'id', 'reply count',\n",
      "       'retweet count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n",
      "Index(['url', 'date', 'content', 'user', 'reply count', 'retweet count',\n",
      "       'like count', 'quote count', 'id', 'language', 'source', 'coordinates',\n",
      "       'dashes'],\n",
      "      dtype='object')\n",
      "Index(['url', 'date', 'content', 'id', 'user', 'reply count', 'retweet count',\n",
      "       'like count', 'quote count', 'conversation id', 'language', 'source',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,5):\n",
    "    print(all_docs[x].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left off after finishing the max calculation loop for problem frames\n",
    "When you come back re-read that section and figure out how to turn it into a function that\n",
    "will operate off of tweets_list\n",
    "\n",
    "Once you finish that you will have a repeateable function that will make sure indecides are correct\n",
    "\n",
    "Then you can start working on fixing column names for all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3 missing column \"url\"\n",
      "Document 4 missing column \"conversation id\"\n"
     ]
    }
   ],
   "source": [
    "#%%script echo skipping\n",
    "# Now that those problem documents are fixed we need to make all the tables\n",
    "# Have the same column names and order of names.\n",
    "# Then find problem columns by checking the column names\n",
    "# against our expected column names.\n",
    "for index, doc in enumerate(all_docs):\n",
    "    rename_list = []\n",
    "    # For dataframe.rename we need a dict with key = current name\n",
    "    # value = desired name\n",
    "    for name in column_names:\n",
    "        if name not in doc.columns.values:\n",
    "            print(f\"Document {index+1} missing column \\\"{name}\\\"\")\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>reply count</th>\n",
       "      <th>retweet count</th>\n",
       "      <th>like count</th>\n",
       "      <th>quote count</th>\n",
       "      <th>conversation id</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/strombone1/status/16202252...</td>\n",
       "      <td>2023-01-31 00:59:29+00:00</td>\n",
       "      <td>https://t.co/ZGWUKFL10w</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>https://twitter.com/strombone1</td>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "      <td>498</td>\n",
       "      <td>6</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>zxx</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/strombone1/status/16202252...</td>\n",
       "      <td>2023-01-31 00:59:27+00:00</td>\n",
       "      <td>I‚Äôm a man of the people. Which helmet should I...</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>https://twitter.com/strombone1</td>\n",
       "      <td>153</td>\n",
       "      <td>51</td>\n",
       "      <td>429</td>\n",
       "      <td>20</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/strombone1/status/16201901...</td>\n",
       "      <td>2023-01-30 22:39:57+00:00</td>\n",
       "      <td>@JessBlaylock @emilymkaplan First line center ...</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>https://twitter.com/strombone1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>412</td>\n",
       "      <td>1</td>\n",
       "      <td>1.62E+18</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/strombone1/status/16056389...</td>\n",
       "      <td>2022-12-21 18:59:02+00:00</td>\n",
       "      <td>And people think Santa doesn‚Äôt exist https://t...</td>\n",
       "      <td>1.61E+18</td>\n",
       "      <td>https://twitter.com/strombone1</td>\n",
       "      <td>177</td>\n",
       "      <td>294</td>\n",
       "      <td>6478</td>\n",
       "      <td>35</td>\n",
       "      <td>1.61E+18</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/strombone1/status/15984627...</td>\n",
       "      <td>2022-12-01 23:43:20+00:00</td>\n",
       "      <td>Finally got my captains photo done https://t.c...</td>\n",
       "      <td>1.60E+18</td>\n",
       "      <td>https://twitter.com/strombone1</td>\n",
       "      <td>155</td>\n",
       "      <td>504</td>\n",
       "      <td>9829</td>\n",
       "      <td>44</td>\n",
       "      <td>1.60E+18</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>https://twitter.com/RafaelNadal/status/1414319...</td>\n",
       "      <td>2021-07-11 20:24:07+00:00</td>\n",
       "      <td>Congrats @DjokerNole on this amazing achieveme...</td>\n",
       "      <td>1414319614474035203</td>\n",
       "      <td>https://twitter.com/RafaelNadal</td>\n",
       "      <td>737</td>\n",
       "      <td>6723</td>\n",
       "      <td>79425</td>\n",
       "      <td>790</td>\n",
       "      <td>1414319614474035203</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>https://twitter.com/RafaelNadal/status/1413228...</td>\n",
       "      <td>2021-07-08 20:10:12+00:00</td>\n",
       "      <td>Hi, everyone! Join me on @FanJoltLive where we...</td>\n",
       "      <td>1413228947802923014</td>\n",
       "      <td>https://twitter.com/RafaelNadal</td>\n",
       "      <td>64</td>\n",
       "      <td>116</td>\n",
       "      <td>1227</td>\n",
       "      <td>11</td>\n",
       "      <td>1413228947802923014</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>https://twitter.com/RafaelNadal/status/1409610...</td>\n",
       "      <td>2021-06-28 20:30:55+00:00</td>\n",
       "      <td>üëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèª</td>\n",
       "      <td>1409610285107789834</td>\n",
       "      <td>https://twitter.com/RafaelNadal</td>\n",
       "      <td>67</td>\n",
       "      <td>176</td>\n",
       "      <td>2879</td>\n",
       "      <td>12</td>\n",
       "      <td>1409610285107789834</td>\n",
       "      <td>art</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>https://twitter.com/RafaelNadal/status/1409610...</td>\n",
       "      <td>2021-06-28 20:30:17+00:00</td>\n",
       "      <td>Partidazo de Espa√±a hoy! üá™üá∏Enhorabuena chicos ...</td>\n",
       "      <td>1409610125724237836</td>\n",
       "      <td>https://twitter.com/RafaelNadal</td>\n",
       "      <td>99</td>\n",
       "      <td>694</td>\n",
       "      <td>11269</td>\n",
       "      <td>41</td>\n",
       "      <td>1409610125724237836</td>\n",
       "      <td>es</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>https://twitter.com/RafaelNadal/status/1407713...</td>\n",
       "      <td>2021-06-23 14:52:20+00:00</td>\n",
       "      <td>üëáüèª</td>\n",
       "      <td>1407713136904388608</td>\n",
       "      <td>https://twitter.com/RafaelNadal</td>\n",
       "      <td>73</td>\n",
       "      <td>147</td>\n",
       "      <td>1844</td>\n",
       "      <td>8</td>\n",
       "      <td>1407713136904388608</td>\n",
       "      <td>art</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5831 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://twitter.com/strombone1/status/16202252...   \n",
       "1     https://twitter.com/strombone1/status/16202252...   \n",
       "2     https://twitter.com/strombone1/status/16201901...   \n",
       "3     https://twitter.com/strombone1/status/16056389...   \n",
       "4     https://twitter.com/strombone1/status/15984627...   \n",
       "...                                                 ...   \n",
       "1195  https://twitter.com/RafaelNadal/status/1414319...   \n",
       "1196  https://twitter.com/RafaelNadal/status/1413228...   \n",
       "1197  https://twitter.com/RafaelNadal/status/1409610...   \n",
       "1198  https://twitter.com/RafaelNadal/status/1409610...   \n",
       "1199  https://twitter.com/RafaelNadal/status/1407713...   \n",
       "\n",
       "                           date  \\\n",
       "0     2023-01-31 00:59:29+00:00   \n",
       "1     2023-01-31 00:59:27+00:00   \n",
       "2     2023-01-30 22:39:57+00:00   \n",
       "3     2022-12-21 18:59:02+00:00   \n",
       "4     2022-12-01 23:43:20+00:00   \n",
       "...                         ...   \n",
       "1195  2021-07-11 20:24:07+00:00   \n",
       "1196  2021-07-08 20:10:12+00:00   \n",
       "1197  2021-06-28 20:30:55+00:00   \n",
       "1198  2021-06-28 20:30:17+00:00   \n",
       "1199  2021-06-23 14:52:20+00:00   \n",
       "\n",
       "                                                content                   id  \\\n",
       "0                               https://t.co/ZGWUKFL10w             1.62E+18   \n",
       "1     I‚Äôm a man of the people. Which helmet should I...             1.62E+18   \n",
       "2     @JessBlaylock @emilymkaplan First line center ...             1.62E+18   \n",
       "3     And people think Santa doesn‚Äôt exist https://t...             1.61E+18   \n",
       "4     Finally got my captains photo done https://t.c...             1.60E+18   \n",
       "...                                                 ...                  ...   \n",
       "1195  Congrats @DjokerNole on this amazing achieveme...  1414319614474035203   \n",
       "1196  Hi, everyone! Join me on @FanJoltLive where we...  1413228947802923014   \n",
       "1197                                   üëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèª  1409610285107789834   \n",
       "1198  Partidazo de Espa√±a hoy! üá™üá∏Enhorabuena chicos ...  1409610125724237836   \n",
       "1199                                                 üëáüèª  1407713136904388608   \n",
       "\n",
       "                                 user reply count retweet count like count  \\\n",
       "0      https://twitter.com/strombone1          70            21        498   \n",
       "1      https://twitter.com/strombone1         153            51        429   \n",
       "2      https://twitter.com/strombone1          15            10        412   \n",
       "3      https://twitter.com/strombone1         177           294       6478   \n",
       "4      https://twitter.com/strombone1         155           504       9829   \n",
       "...                               ...         ...           ...        ...   \n",
       "1195  https://twitter.com/RafaelNadal         737          6723      79425   \n",
       "1196  https://twitter.com/RafaelNadal          64           116       1227   \n",
       "1197  https://twitter.com/RafaelNadal          67           176       2879   \n",
       "1198  https://twitter.com/RafaelNadal          99           694      11269   \n",
       "1199  https://twitter.com/RafaelNadal          73           147       1844   \n",
       "\n",
       "     quote count      conversation id language  \\\n",
       "0              6             1.62E+18      zxx   \n",
       "1             20             1.62E+18       en   \n",
       "2              1             1.62E+18       en   \n",
       "3             35             1.61E+18       en   \n",
       "4             44             1.60E+18       en   \n",
       "...          ...                  ...      ...   \n",
       "1195         790  1414319614474035203       en   \n",
       "1196          11  1413228947802923014       en   \n",
       "1197          12  1409610285107789834      art   \n",
       "1198          41  1409610125724237836       es   \n",
       "1199           8  1407713136904388608      art   \n",
       "\n",
       "                                                 source coordinates  \n",
       "0     <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "1     <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "2     <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "3     <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "4     <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "...                                                 ...         ...  \n",
       "1195  <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "1196  <a href=\"https://mobile.twitter.com\" rel=\"nofo...         NaN  \n",
       "1197  <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "1198  <a href=\"http://twitter.com/download/iphone\" r...         NaN  \n",
       "1199  <a href=\"https://mobile.twitter.com\" rel=\"nofo...         NaN  \n",
       "\n",
       "[5831 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With the previous cell we make sure all column names are present.\n",
    "# Now we need to reorder them\n",
    "corpus = pd.concat(all_docs)\n",
    "corpus.drop(labels=\"dashes\",axis=1,inplace=True)\n",
    "display(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "corpus.to_csv(path_or_buf=\"all_tweets_group_4.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "36647a1b87c30035800aeb35dbc18fb40497493772dd70794ded5d2d651847c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
